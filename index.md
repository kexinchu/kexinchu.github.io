---
layout: default
title: "Kexin Chu | Academic Homepage"
---

# 👋 Welcome to the Homepage of <span style="color:#c0392b"><b>Kexin Chu</b></span>

Ph.D. student at University of Connecticut, focusing on <span style="color:#27ae60"><b>Machine Learning Systems</b></span>, <span style="color:#27ae60"><b>LLM infra</b></span>, <span style="color:#27ae60"><b>System Security</b></span>, and <span style="color:#27ae60"><b>Disaggregated Memory</b></span>. I am passionate about building efficient and secure infrastructures for large-scale AI models, particularly in KV-cache sharing, memory-aware scheduling, and RDMA-based systems.

📍 Currently based in Connecticut, USA.  
🔗 [Google Scholar](https://scholar.google.com/citations?user=ZIdS3d0AAAAJ&hl=en) | [GitHub](https://github.com/kexinchu) | kexin.chu@uconn.edu

---

## 🧪 Research Interests

- Large Language Models (LLMs)
- Efficient ML Systems
- Security in ML systems
- RDMA and memory-tiered systems
- CXL

---

## 📄 Selected Publications

- **MCaM: Efficient LLM Inference with Multi-tier KV Cache Management**  
  🔹 *To appear at ICDCS'2025*

- **SafeKV: Safe KV-Cache Sharing in LLM Serving**  
  🔹 *To appear at MLArhSys'2025 | ISCA'2025*

- **CaR: An Efficient KV Cache Reuse System for Large Language Model Inference**  
  🔗 [link](hhttps://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZIdS3d0AAAAJ&citation_for_view=ZIdS3d0AAAAJ:9yKSN-GCB0IC)  
  🔹 *LG-ARC'2024 | ISCA'2024*
---

## 🎓 Education

- **Ph.D. in Computer Science**, University of Connecticut, USA  
  _Research in ML systems, KV-cache optimization, RDMA-backed storage_

- **M.S. in Integrated Circuit Engineering**, Hefei University of Technology, China  
  _Co-supervised by A.P. Ying Wang and A.P. Cheng Liu_  
  _Specialized in computer architecture and AI acceleration_

- **B.S. in Integrated Circuit Design & Integrated System**, Hefei University of Technology, China  

---

## 💼 Industry Experience

**Baidu Inc., Beijing, China**  
_Software Architect & Backend Engineer (2020–2024)_
- Worked in the Search R&D Platform department, focusing on large-scale backend systems.
- Promoted from T3 → T4 in 2021, and T4 → T5 in 2023 for top-tier performance.
- Key areas of work included:
    - DeepQA Web Services using C++/brpc for search applications with high traffic.
    - LLM Access Control Systems supporting Ernie Bot user management (Golang, Redis, MySQL).
    - Real-Time Streaming Systems for indexing and ingesting large-scale data (Kafka-based).

---

## 🏆 Honors & Awards

- 🏅 Predoctoral Fellowship, UConn (2025)  
- 🏅 Baidu Pride Special Award (2022)  
- 🎓 National Schinfrastructureolarship (2018, 2019)

---